{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  DSC478 - Programming Machine Learning Applications\n",
    "## Assignment 4 - Lavinia Wang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2. Item-Based Joke Recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a modified version of the item-based recommender algorithm from Ch.14 of Machine Learning in Action and use it on joke ratings data based on Jester Online Joke Recommender System. The modified version of the code is provided in the module itemBasedRec.py. Most of the module will be used as is, but you will add some additional functionality. The data set contains two files. The file \"modified_jester_data.csv\" contains the ratings on 100 jokes by 1000 users (each row is a user profile). The ratings have been normalized to be between 1 and 21 (a 20-point scale), with 1 being the lowest rating. A zero indicated a missing rating. The file \"jokes.csv\" contains the joke ids mapped to the actual text of the jokes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset: <a href='http://facweb.cs.depaul.edu/mobasher/classes/CSC478/Data/jokes.zip'>jokes.zip</a> Dataset description <a href='http://eigentaste.berkeley.edu/dataset/'>here</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os \n",
    "\n",
    "from numpy import *\n",
    "from numpy import linalg as la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change working directory\n",
    "os.chdir('/resources/CSC478/Assignment4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Load in the joke ratings data and the joke text data into appropriate data structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 100)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = np.genfromtxt('modified_jester_data.csv', delimiter=',')\n",
    "ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "jokes = np.genfromtxt('jokes.csv',delimiter=',',dtype=str)\n",
    "jokes = np.array(jokes[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A man visits the doctor. The doctor says \"I have bad news for you.You have cancer and Alzheimer\\'s disease\". The man replies \"Well thank God I don\\'t have cancer!\"',\n",
       "       'This couple had an excellent relationship going until one day he came home from work to find his girlfriend packing. He asked her why she was leaving him and she told him that she had heard awful things about him. \"What could they possibly have said to make you move out?\" \"They told me that you were a pedophile.\" He replied \"That\\'s an awfully big word for a ten year old.\"',\n",
       "       \"Q. What's 200 feet long and has 4 teeth? A. The front row at a Willie Nelson Concert.\",\n",
       "       \"Q. What's the difference between a man and a toilet? A. A toilet doesn't follow you around after you use it.\",\n",
       "       \"Q. What's O. J. Simpson's Internet address? A.\\tSlash slash backslash slash slash escape.\"],\n",
       "      dtype='<U1198')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jokes[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jokes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(0.2*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Complete the definition for the function \"test\". This function iterates over all users and for each performs evaluation (by calling the provided \"cross_validate_user\" function), and returns the error information necessary to compute Mean Absolute Error (MAE). Use this function to perform evaluation (with 20% testratio for each user) comparing MAE results using standard item-based collaborative filtering (based on the rating prediction function \"standEst\") with results using the SVD-based version of the rating item-based CF (using \"svdEst\" as the prediction engine). [Note: See comments provided in the module for hints on accomplishing these tasks.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "from numpy import linalg as la\n",
    "import numpy as np\n",
    "\n",
    "def ecludSim(inA,inB):\n",
    "    return 1.0 / (1.0 + la.norm(inA - inB))\n",
    "\n",
    "def pearsSim(inA,inB):\n",
    "    if len(inA) < 3 : return 1.0\n",
    "    return 0.5 + 0.5 * corrcoef(inA, inB, rowvar = 0)[0][1]\n",
    "\n",
    "def cosSim(inA,inB):\n",
    "    num = float(inA.T * inB)\n",
    "    denom = la.norm(inA)*la.norm(inB)\n",
    "    return 0.5 + 0.5 * (num / denom)\n",
    "\n",
    "def standEst(dataMat, user, simMeas, item):\n",
    "    n = shape(dataMat)[1]\n",
    "    simTotal = 0.0; ratSimTotal = 0.0\n",
    "    for j in range(n):\n",
    "        userRating = dataMat[user,j]\n",
    "        if userRating == 0: continue\n",
    "        overLap = nonzero(logical_and(dataMat[:,item]>0, \\\n",
    "                                      dataMat[:,j]>0))[0]\n",
    "        if len(overLap) == 0: similarity = 0\n",
    "        else: similarity = simMeas(dataMat[overLap,item], \\\n",
    "                                   dataMat[overLap,j])\n",
    "        #print 'the %d and %d similarity is: %f' % (item, j, similarity)\n",
    "        simTotal += similarity\n",
    "        ratSimTotal += similarity * userRating\n",
    "    if simTotal == 0: return 0\n",
    "    else: return ratSimTotal/simTotal\n",
    "    \n",
    "def svdEst(dataMat, user, simMeas, item):\n",
    "    n = shape(dataMat)[1]\n",
    "    simTotal = 0.0; ratSimTotal = 0.0\n",
    "    data=mat(dataMat)\n",
    "    U,Sigma,VT = la.svd(data)\n",
    "    Sig4 = mat(eye(4)*Sigma[:4]) #arrange Sig4 into a diagonal matrix\n",
    "    xformedItems = data.T * U[:,:4] * Sig4.I  #create transformed items\n",
    "    for j in range(n):\n",
    "        userRating = data[user,j]\n",
    "        if userRating == 0 or j==item: continue\n",
    "        similarity = simMeas(xformedItems[item,:].T,\\\n",
    "                             xformedItems[j,:].T)\n",
    "        #print 'the %d and %d similarity is: %f' % (item, j, similarity)\n",
    "        simTotal += similarity\n",
    "        ratSimTotal += similarity * userRating\n",
    "    if simTotal == 0: return 0\n",
    "    else: return ratSimTotal/simTotal\n",
    "\n",
    "# This function is not needed for Assignment 4, but may be useful for experimentation\n",
    "def recommend(dataMat, user, N=3, simMeas=cosSim, estMethod=standEst):\n",
    "    unratedItems = nonzero(dataMat[user,:].A==0)[1] #find unrated items \n",
    "    if len(unratedItems) == 0: return 'you rated everything'\n",
    "    itemScores = []\n",
    "    for item in unratedItems:\n",
    "        estimatedScore = estMethod(dataMat, user, simMeas, item)\n",
    "        itemScores.append((item, estimatedScore))\n",
    "    return sorted(itemScores, key=lambda jj: jj[1], reverse=True)[:N]\n",
    "\n",
    "# This function performs cross-validation on a single user based on the test_ratio\n",
    "# For example, with test_ratio = 0.2, 5-fold x-validation is performed where in each fold, \n",
    "# 20 percent of rated items are withheld and the rest are used to estimate the withheld ratings\n",
    "\n",
    "def cross_validate_user(dataMat, user, test_ratio, estMethod=standEst, simMeas=pearsSim):\n",
    "    number_of_items = np.shape(dataMat)[1]\n",
    "    rated_items_by_user = np.array([i for i in range(number_of_items) if dataMat[user,i]>0])\n",
    "    test_size = int(test_ratio * len(rated_items_by_user))\n",
    "    test_indices = np.random.randint(0, len(rated_items_by_user), test_size)\n",
    "    withheld_items = rated_items_by_user[test_indices]\n",
    "    original_user_profile = np.copy(dataMat[user])\n",
    "    dataMat[user, withheld_items] = 0 # So that the withheld test items is not used in the rating estimation below\n",
    "    error_u = 0.0\n",
    "    count_u = len(withheld_items)\n",
    "\n",
    "    # Compute absolute error for user u over all test items\n",
    "    for item in withheld_items:\n",
    "        # Estimate rating on the withheld item\n",
    "        estimatedScore = estMethod(dataMat, user, simMeas, item)\n",
    "        error_u = error_u + abs(estimatedScore - original_user_profile[item])\t\n",
    "    \n",
    "    # Now restore ratings of the withheld items to the user profile\n",
    "    for item in withheld_items:\n",
    "        dataMat[user, item] = original_user_profile[item]\n",
    "        \n",
    "    # Return sum of absolute errors and the count of test cases for this user\n",
    "    # Note that these will have to be accumulated for each user to compute MAE\n",
    "    return error_u, count_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataMat, test_ratio, estMethod):\n",
    "    # Write this function to iterate over all users and for each perform cross-validation on items by calling\n",
    "    # the above cross-validation function on each user.\n",
    "    # MAE will be the ratio of total error across all test cases to the total number of test cases, for all users\n",
    "    \n",
    "    #row = dataMat[0,]\n",
    "    #print \"A row is: \", row\n",
    "    total_error=0.0\n",
    "    total_count=0\n",
    "    for user in range(dataMat.shape[0]):\n",
    "        error, count = cross_validate_user(dataMat, user, .2, estMethod)\n",
    "        total_error = total_error + error\n",
    "        total_count = total_count + count\n",
    "    MAE = total_error/total_count\n",
    "    print ('Mean Absoloute Error for ',estMethod,' : ', MAE)\n",
    "    return MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' See example output below:\\n\\nSelected joke: \\n\\nQ. What\\'s the difference between a man and a toilet? A. A toilet doesn\\'t follow you around after you use it.\\n\\nTop 5 Recommended jokes are :\\n\\nQ: What\\'s the difference between a Lawyer and a Plumber? A: A Plumber works to unclog the system. \\n_______________\\nWhat do you call an American in the finals of the world cup? \"Hey Beer Man!\" \\n_______________\\nQ. What\\'s 200 feet long and has 4 teeth? <P>A. The front row at a Willie Nelson Concert. \\n_______________\\nA country guy goes into a city bar that has a dress code and the maitred\\' demands he wear a tie. Discouraged the guy goes to his car to sulk when inspiration strikes: He\\'s got jumper cables in the trunk! So he wrapsthem around his neck sort of like a string tie (a bulky string tie to be sure) and returns to the bar. The maitre d\\' is reluctant but says to the guy \"Okay you\\'re a pretty resourceful fellow you can come in... but just don\\'t start anything\"!   \\n_______________\\nWhat do you get when you run over a parakeet with a lawnmower? <P>Shredded tweet. \\n_______________\\n\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def kNearestNeighbors(inX, dataSet, k, measure):\n",
    "    distances = []\n",
    "    for i in range(dataSet.shape[1]):\n",
    "        vector = dataSet[:,i]\n",
    "        distance = measure(inX, vector)\n",
    "        distances.append(distance)\n",
    "    #print \"Before, distances is: \", distances\n",
    "    distancesArray = np.array(distances)\n",
    "    #print \"After, distances is: \", distancesArray\n",
    "    sortedDistIndicies = distancesArray.argsort()\n",
    "    kNeighbors = zeros((k,dataSet.shape[1]))\n",
    "    topIndicies = []\n",
    "    classCount={}\n",
    "    for i in range(k):\n",
    "        #voteIlabel = labels[sortedDistIndicies[i]]\n",
    "        kNeighbors[i,:] = dataSet[sortedDistIndicies[i],:]\n",
    "        topIndicies.append(sortedDistIndicies[i])\n",
    "        #print \"sortedDistIndices: is\", sortedDistIndicies\n",
    "        #print \"kNeighbors is: \", kNeighbors\n",
    "        #classCount[voteIlabel] = classCount.get(voteIlabel,0) + 1\n",
    "    #sortedClassCount = sorted(classCount.iteritems(),key=operator.itemgetter(1), reverse=True)\n",
    "    return kNeighbors, topIndicies  #, sortedClassCount[0][0]\n",
    "\n",
    "def load_jokes(file):\n",
    "    jokes = genfromtxt(file, delimiter=',', dtype=str)\n",
    "    jokes = np.array(jokes[:,1])\n",
    "    return jokes\n",
    "\n",
    "def get_joke_text(jokes, id):\n",
    "    return jokes[id]\n",
    "\n",
    "# dataMat = genfromtxt('modified_jester_data.csv',delimiter=',')\n",
    "\n",
    "# test(dataMat, 0.2, svdEst)\n",
    "# test(dataMat, 0.2, standEst)\n",
    "\n",
    "# jokes = load_jokes('jokes.csv')\n",
    "# print_most_similar_jokes(dataMat, jokes, 3, 5, pearsSim)\n",
    "\n",
    "''' See example output below:\n",
    "\n",
    "Selected joke: \n",
    "\n",
    "Q. What's the difference between a man and a toilet? A. A toilet doesn't follow you around after you use it.\n",
    "\n",
    "Top 5 Recommended jokes are :\n",
    "\n",
    "Q: What's the difference between a Lawyer and a Plumber? A: A Plumber works to unclog the system. \n",
    "_______________\n",
    "What do you call an American in the finals of the world cup? \"Hey Beer Man!\" \n",
    "_______________\n",
    "Q. What's 200 feet long and has 4 teeth? <P>A. The front row at a Willie Nelson Concert. \n",
    "_______________\n",
    "A country guy goes into a city bar that has a dress code and the maitred' demands he wear a tie. Discouraged the guy goes to his car to sulk when inspiration strikes: He's got jumper cables in the trunk! So he wrapsthem around his neck sort of like a string tie (a bulky string tie to be sure) and returns to the bar. The maitre d' is reluctant but says to the guy \"Okay you're a pretty resourceful fellow you can come in... but just don't start anything\"!   \n",
    "_______________\n",
    "What do you get when you run over a parakeet with a lawnmower? <P>Shredded tweet. \n",
    "_______________\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absoloute Error for  <function standEst at 0x3fff68d51a60>  :  3.6936801967915636\n",
      "CPU times: user 1min 51s, sys: 4 ms, total: 1min 51s\n",
      "Wall time: 1min 51s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.6936801967915636"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "test(ratings, .2, standEst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absoloute Error for  <function svdEst at 0x3fff68d516a8>  :  3.612726394645625\n",
      "CPU times: user 21min 47s, sys: 20 ms, total: 21min 47s\n",
      "Wall time: 21min 47s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.612726394645625"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "test(ratings,.2, svdEst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. Write a new function \"print_most_similar_jokes\" which takes the joke ratings data, a query joke id, a parameter k for the number of nearest neighbors, and a similarity metric function, and prints the text of the query joke as well as the texts of the top k most similar jokes based on user ratings. [Note: For hints on how to accomplish this task, please see comments at the end of the provided module as well as comments for the provided stub function.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_most_similar_jokes(dataMat, jokes, queryJoke, k, metric=pearsSim):\n",
    "    # Write this function to find the k most similar jokes (based on user ratings) to a queryJoke\n",
    "    # The queryJoke is a joke id as given in the 'jokes.csv' file (an corresponding to the a column in dataMat)\n",
    "    # You must compare ratings for the queryJoke (the column in dataMat corresponding to the joke), to all\n",
    "    # other joke rating vectors and return the top k. Note that this is the same as performing KNN on the \n",
    "    # columns of dataMat. The function must retrieve the text of the joke from 'jokes.csv' file and print both\n",
    "    # the queryJoke text as well as the text of the returned jokes.\n",
    "    queryJokeVector = dataMat[:,queryJoke]\n",
    "    print (\"Selcted joke: \")\n",
    "    print()\n",
    "    print (jokes[queryJoke])\n",
    "    print()\n",
    "    dataMatArray = np.array(dataMat)\n",
    "    knn, indicies = kNearestNeighbors(queryJokeVector, dataMat, k, metric)\t\n",
    "    print (\"The top %d recommended jokes are: \"%(k))\n",
    "    for ind in indicies:\n",
    "        jok = jokes[ind]\n",
    "        print()\n",
    "        print (jok)\n",
    "    #print \"Done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selcted joke: \n",
      "\n",
      "Q. What's the difference between a man and a toilet? A. A toilet doesn't follow you around after you use it.\n",
      "\n",
      "The top 5 recommended jokes are: \n",
      "\n",
      "A dog walks into Western Union and asks the clerk to send a telegram. He fills out a form on which he writes down the telegram he wishes to send: \"Bow wow wow Bow wow wow.\"The clerk says \"You can add another 'Bow wow' for the same price.\"The dog responded \"Now wouldn't that sound a little silly?\"\n",
      "\n",
      "Q:  What did the blind person say when given some matzah?A:  Who the hell wrote this?\n",
      "\n",
      "Q. Did you hear about the dyslexic devil worshipper? A. He sold his soul to Santa.\n",
      "\n",
      "Q. What is orange and sounds like a parrot?  A. A carrot.\n",
      "\n",
      "A guy goes into confession and says to the priest \"Father I'm 80 years old widower with 11 grandchildren. Last night I met two beautiful flight attendants. They took me home and I made love to both of them. Twice.\"The priest said: \"Well my son when was the last time you were in confession?\" \"Never Father I'm Jewish.\" \"So then why are you telling me?\" \"I'm telling everybody.\"\n"
     ]
    }
   ],
   "source": [
    "print_most_similar_jokes(ratings, jokes, 3, 5, pearsSim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
